{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jlJBSZkBez60"
   },
   "source": [
    "# 과제1: tensorflow를 이용한 NN 밑바닥부터 구현\n",
    "input feature가 100개이고,  \n",
    "hidden layer가 2개이고 neuron이 각각 50,10개이고,  \n",
    "output이 5개인 NN를 구현해 보자  \n",
    "* hidden layer는 relu를 activation function으로, output layer는 softmax를 activation function으로 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\shong\\appdata\\roaming\\python\\python38\\site-packages (2.4.1)\n",
      "Requirement already satisfied: termcolor~=1.1.0 in c:\\users\\shong\\appdata\\roaming\\python\\python38\\site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: flatbuffers~=1.12.0 in c:\\users\\shong\\appdata\\roaming\\python\\python38\\site-packages (from tensorflow) (1.12)\n",
      "Requirement already satisfied: opt-einsum~=3.3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: wheel~=0.35 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (0.35.1)\n",
      "Requirement already satisfied: gast==0.3.3 in c:\\users\\shong\\appdata\\roaming\\python\\python38\\site-packages (from tensorflow) (0.3.3)\n",
      "Requirement already satisfied: six~=1.15.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (2.4.0)\n",
      "Requirement already satisfied: absl-py~=0.10 in c:\\users\\shong\\appdata\\roaming\\python\\python38\\site-packages (from tensorflow) (0.11.0)\n",
      "Requirement already satisfied: astunparse~=1.6.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: typing-extensions~=3.7.4 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (3.7.4.3)\n",
      "Requirement already satisfied: numpy~=1.19.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (1.19.2)\n",
      "Requirement already satisfied: wrapt~=1.12.1 in c:\\users\\shong\\appdata\\roaming\\python\\python38\\site-packages (from tensorflow) (1.12.1)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in c:\\users\\shong\\appdata\\roaming\\python\\python38\\site-packages (from tensorflow) (3.14.0)\n",
      "Requirement already satisfied: grpcio~=1.32.0 in c:\\users\\shong\\appdata\\roaming\\python\\python38\\site-packages (from tensorflow) (1.32.0)\n",
      "Requirement already satisfied: keras-preprocessing~=1.1.2 in c:\\users\\shong\\appdata\\roaming\\python\\python38\\site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: google-pasta~=0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py~=2.10.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (2.10.0)\n",
      "Requirement already satisfied: tensorboard~=2.4 in c:\\users\\shong\\appdata\\roaming\\python\\python38\\site-packages (from tensorflow) (2.4.1)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in c:\\users\\shong\\appdata\\roaming\\python\\python38\\site-packages (from tensorboard~=2.4->tensorflow) (1.24.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard~=2.4->tensorflow) (50.3.1.post20201107)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\shong\\appdata\\roaming\\python\\python38\\site-packages (from tensorboard~=2.4->tensorflow) (0.4.2)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard~=2.4->tensorflow) (2.24.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\shong\\appdata\\roaming\\python\\python38\\site-packages (from tensorboard~=2.4->tensorflow) (3.3.3)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\shong\\appdata\\roaming\\python\\python38\\site-packages (from tensorboard~=2.4->tensorflow) (1.8.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard~=2.4->tensorflow) (1.0.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in c:\\users\\shong\\appdata\\roaming\\python\\python38\\site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (4.7)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\shong\\appdata\\roaming\\python\\python38\\site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in c:\\users\\shong\\appdata\\roaming\\python\\python38\\site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (4.2.1)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\shong\\appdata\\roaming\\python\\python38\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow) (1.3.0)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (1.25.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (2020.6.20)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (3.0.4)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in c:\\users\\shong\\appdata\\roaming\\python\\python38\\site-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\shong\\appdata\\roaming\\python\\python38\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow) (3.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "executionInfo": {
     "elapsed": 2466,
     "status": "ok",
     "timestamp": 1612097621689,
     "user": {
      "displayName": "Yoojin Song",
      "photoUrl": "",
      "userId": "14550345553948958105"
     },
     "user_tz": -540
    },
    "id": "zEsHRO5Fez7A",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "executionInfo": {
     "elapsed": 2460,
     "status": "ok",
     "timestamp": 1612097621692,
     "user": {
      "displayName": "Yoojin Song",
      "photoUrl": "",
      "userId": "14550345553948958105"
     },
     "user_tz": -540
    },
    "id": "kqxF8Vffez7C"
   },
   "outputs": [],
   "source": [
    "n_x = 100\n",
    "n_h1 = 50\n",
    "n_h2 = 10\n",
    "n_y = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2449,
     "status": "ok",
     "timestamp": 1612097621693,
     "user": {
      "displayName": "Yoojin Song",
      "photoUrl": "",
      "userId": "14550345553948958105"
     },
     "user_tz": -540
    },
    "id": "SsmSgB5hez7C",
    "outputId": "5cf3c607-a796-4fbc-b225-c262ee2db512"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.2124896  -0.21180828 -0.08910526 ...  0.99292123  0.8294151\n",
      "  -0.01366135]\n",
      " [-1.348126    0.2476664   0.6406654  ... -1.296355   -1.9140676\n",
      "  -0.15290621]\n",
      " [ 1.3948125   0.60749257 -0.32510254 ... -0.76768476  0.4577213\n",
      "   0.7250878 ]\n",
      " ...\n",
      " [ 1.8825585   1.2281501   1.147263   ... -1.7443273   0.04199841\n",
      "   0.04566711]\n",
      " [-0.09637723  0.30329362 -0.31719157 ... -0.13620797  1.8866997\n",
      "  -1.1594032 ]\n",
      " [ 0.2885809  -1.7707328  -0.7536415  ... -0.32551527 -0.7265424\n",
      "   0.6501261 ]]\n",
      "[[0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " ...\n",
      " [1. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# Simulate train set\n",
    "m = 500\n",
    "\n",
    "x_train=np.random.randn(m,n_x).astype(np.float32)\n",
    "y_train=np.zeros((m,n_y)).astype(np.float32)\n",
    "y_train[np.arange(m),np.random.randint(n_y,size=m)]=1\n",
    "\n",
    "print(x_train)\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gcqp4J2Iez7D"
   },
   "source": [
    "* Initialization of weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "LZlWhE_-ez7E"
   },
   "outputs": [],
   "source": [
    "w1=tf.Variable(1e-3*np.random.randn(n_x,n_h1).astype(np.float32),name=\"w1\")\n",
    "## 코드를 작성해 보세요 ##\n",
    "w2=tf.Variable(1e-3*np.random.randn(n_h1,n_h2).astype(np.float32),name=\"w2\")\n",
    "w3=tf.Variable(1e-3*np.random.randn(n_h2,n_y).astype(np.float32),name=\"w3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5dZOinUiez7E"
   },
   "source": [
    "* forward propagation을 통해 prediction 값을 구하고, loss를 구하는 function을 만들어 봅시다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "ColOfYYLez7F"
   },
   "outputs": [],
   "source": [
    "def forward(x):\n",
    "    z1=tf.matmul(x,w1)\n",
    "    a1=tf.nn.relu(z1)\n",
    "    z2=tf.matmul(a1,w2)\n",
    "    a2=tf.nn.relu(z2)\n",
    "    z3=tf.matmul(a2,w3)\n",
    "    predictions = tf.nn.softmax(z3)\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "def loss_fn(predictions, y):\n",
    "    loss= -tf.reduce_sum(y*tf.math.log(predictions))\n",
    "    return loss    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "upUgNiSAez7F"
   },
   "source": [
    "* backpropagation & update parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "mo4llpE1ez7G"
   },
   "outputs": [],
   "source": [
    "learning_rate=1e-2\n",
    "optimizer=tf.keras.optimizers.Adam(learning_rate)\n",
    "\n",
    "def train_step(x, y):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = forward(x)\n",
    "        loss = loss_fn(predictions, y)\n",
    "    gradient = tape.gradient(loss, [w1, w2])\n",
    "    \n",
    "    # optimizer와 위에서 구한 경사도를 이용해 가중치들을 업데이트 합니다.\n",
    "    optimizer.apply_gradients(zip(gradient, [w1, w2]))\n",
    "    return loss, w1, w2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SCQVuWu0ez7H"
   },
   "source": [
    "* 간단하게 train loop를 작성해 loss가 줄어나가는지 확인해 봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "rRL-dNg3ez7H"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[804.7188, 804.71796, 804.70636, 804.68195, 804.6398, 804.5768, 804.48987, 804.3779, 804.2382, 804.0683]\n"
     ]
    }
   ],
   "source": [
    "loss_list = []\n",
    "\n",
    "for step in range(10): \n",
    "    loss, w1, w2 = train_step(x_train, y_train)\n",
    "    loss_list.append(loss.numpy())\n",
    "    \n",
    "print(loss_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cEnMiFyYez7H"
   },
   "source": [
    "# 과제2: MNIST 데이터를 나만의 NN model로 95 % 이상의 성능으로 training 시켜보자!\n",
    "\n",
    "\n",
    "## Loading MNIST training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "MZftDy_Uez7I"
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "# import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Loading the data\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "# Scaling(image data는 min-max scaling 주로 사용)\n",
    "x_train = x_train/255.0\n",
    "x_test = x_test/255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RTznVP7_ez7I"
   },
   "source": [
    "## Training Data\n",
    "28 * 28 pixel 값을 가진 총 60000개의 이미지 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "IGJVObIIez7J"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-_Uj_sOMez7J"
   },
   "source": [
    "Neural network 모델에 맞게 이미지 데이터를 벡터 형태로 데이터를 reshape 합니다.  \n",
    "(Model을 만들 때 *keras.layers.Flatten(input_shape=(28, 28)) 이용해도 됨)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "m3xVE5QYez7J"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 784), (10000, 784))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, x_test = x_train.reshape((-1, 28*28)), x_test.reshape((-1, 28*28))\n",
    "x_train.shape, x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "kZccDzM7ez7K"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "tmp = np.reshape(x_train[0], (28, 28))\n",
    "plt.imshow(tmp).set_cmap('Greys')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_LurnKdPez7K"
   },
   "source": [
    "## Training Labels\n",
    "이미지 데이터가 나타내는 숫자값을 label로 가지고 있고, 0부터 9까지의 값을 나타냄  \n",
    "마찬가지로, 60000개의 label이 존재"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "xx5TtXsOez7K"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000,)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "tLni5O5Qez7L"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show MNIST label for above data\n",
    "y_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yT5-hGoXez7L"
   },
   "source": [
    "## 나만의 모델을 tensorflow keras API 를 이용해 만들어 봅시다~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pa_8sRA6ez7L"
   },
   "source": [
    "* parameters for model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "ytVZatEuez7M"
   },
   "outputs": [],
   "source": [
    "activation_list = [\"sigmoid\", \"relu\", \"softmax\", \"tanh\"]\n",
    "\n",
    "loss_list = [\"sparse_categorical_crossentropy\",\n",
    "             \"categorical_crossentropy\", \n",
    "             \"binary_crossentropy\"]\n",
    "\n",
    "optimizer_list = [\"sgd\", \"adam\", \"rmsprop\", \"adagrad\"]\n",
    "\n",
    "initializer_list = [tf.keras.initializers.RandomNormal(), \n",
    "                    tf.keras.initializers.RandomUniform(), \n",
    "                    tf.keras.initializers.he_normal(), \n",
    "                    tf.keras.initializers.he_uniform(), \n",
    "                    tf.keras.initializers.GlorotUniform(),\n",
    "                    tf.keras.initializers.GlorotNormal()]\n",
    "\n",
    "# dropout\n",
    "dropout_rate = 0.3\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(256, input_dim=784, activation = \"sigmoid\"),\n",
    "    tf.keras.layers.Dense(2, activation = \"sigmoid\"),\n",
    "    tf.keras.layers.Dropout(dropout_rate)\n",
    "])\n",
    "\n",
    "\n",
    "# regularizer\n",
    "regularizer = tf.keras.regularizers.l1(1e-3)\n",
    "regularizer = tf.keras.regularizers.l2(1e-3)\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(256, input_dim=784, activation=\"sigmoid\",\n",
    "                          activity_regularizer=regularizer)\n",
    "])\n",
    "\n",
    "# weight initialization\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(256, input_dim=784, activation=\"sigmoid\",\n",
    "                          kernel_initializer=initializer_list[0])\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Je5FAmX1ez7M"
   },
   "source": [
    "#### My Own Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "id": "81GpyDsnez7N"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(300, input_dim=784, activation='relu', kernel_initializer=tf.keras.initializers.RandomNormal()),\n",
    "    tf.keras.layers.Dropout(rate=0.3),\n",
    "    tf.keras.layers.Dense(100, activation='relu' ,kernel_initializer=tf.keras.initializers.RandomNormal()),\n",
    "    tf.keras.layers.Dropout(rate=0.3),\n",
    "    tf.keras.layers.Dense(50, activation='relu', kernel_initializer=tf.keras.initializers.RandomNormal()),\n",
    "    tf.keras.layers.Dropout(rate=0.3),\n",
    "    tf.keras.layers.Dense(10, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_54 (Dense)             (None, 300)               235500    \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense_55 (Dense)             (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_56 (Dense)             (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dropout_22 (Dropout)         (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_57 (Dense)             (None, 10)                510       \n",
      "=================================================================\n",
      "Total params: 271,160\n",
      "Trainable params: 271,160\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = \"sparse_categorical_crossentropy\", \n",
    "              optimizer = 'adam',\n",
    "              metrics = [\"accuracy\"]\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.1720 - accuracy: 0.9640 - val_loss: 0.1173 - val_accuracy: 0.9735\n",
      "Epoch 2/30\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.1174 - accuracy: 0.9672 - val_loss: 0.1149 - val_accuracy: 0.9737\n",
      "Epoch 3/30\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.1117 - accuracy: 0.9691 - val_loss: 0.1034 - val_accuracy: 0.9747\n",
      "Epoch 4/30\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.1014 - accuracy: 0.9716 - val_loss: 0.1038 - val_accuracy: 0.9758\n",
      "Epoch 5/30\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.0965 - accuracy: 0.9740 - val_loss: 0.1064 - val_accuracy: 0.9773\n",
      "Epoch 6/30\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.0879 - accuracy: 0.9749 - val_loss: 0.1054 - val_accuracy: 0.9775\n",
      "Epoch 7/30\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.0815 - accuracy: 0.9777 - val_loss: 0.1054 - val_accuracy: 0.9795\n",
      "Epoch 8/30\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.0818 - accuracy: 0.9761 - val_loss: 0.1130 - val_accuracy: 0.9773\n",
      "Epoch 9/30\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.0741 - accuracy: 0.9780 - val_loss: 0.1140 - val_accuracy: 0.9769\n",
      "Epoch 10/30\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.0719 - accuracy: 0.9806 - val_loss: 0.1025 - val_accuracy: 0.9774\n",
      "Epoch 11/30\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.0682 - accuracy: 0.9800 - val_loss: 0.1072 - val_accuracy: 0.9790\n",
      "Epoch 12/30\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.0634 - accuracy: 0.9820 - val_loss: 0.0978 - val_accuracy: 0.9784\n",
      "Epoch 13/30\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.0595 - accuracy: 0.9827 - val_loss: 0.1076 - val_accuracy: 0.9774\n",
      "Epoch 14/30\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.0629 - accuracy: 0.9806 - val_loss: 0.1059 - val_accuracy: 0.9772\n",
      "Epoch 15/30\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.0585 - accuracy: 0.9835 - val_loss: 0.1096 - val_accuracy: 0.9797\n",
      "Epoch 16/30\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.0571 - accuracy: 0.9828 - val_loss: 0.1039 - val_accuracy: 0.9788\n",
      "Epoch 17/30\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.0548 - accuracy: 0.9834 - val_loss: 0.1033 - val_accuracy: 0.9793\n",
      "Epoch 18/30\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.0509 - accuracy: 0.9866 - val_loss: 0.1042 - val_accuracy: 0.9790\n",
      "Epoch 19/30\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.0499 - accuracy: 0.9866 - val_loss: 0.1104 - val_accuracy: 0.9806\n",
      "Epoch 20/30\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.0487 - accuracy: 0.9865 - val_loss: 0.1335 - val_accuracy: 0.9757\n",
      "Epoch 21/30\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.0534 - accuracy: 0.9858 - val_loss: 0.1132 - val_accuracy: 0.9787\n",
      "Epoch 22/30\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.0491 - accuracy: 0.9858 - val_loss: 0.1163 - val_accuracy: 0.9803\n",
      "Epoch 23/30\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.0510 - accuracy: 0.9857 - val_loss: 0.1044 - val_accuracy: 0.9809\n",
      "Epoch 24/30\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.0424 - accuracy: 0.9873 - val_loss: 0.1120 - val_accuracy: 0.9805\n",
      "Epoch 25/30\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.0508 - accuracy: 0.9862 - val_loss: 0.1203 - val_accuracy: 0.9809\n",
      "Epoch 26/30\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.0430 - accuracy: 0.9879 - val_loss: 0.1275 - val_accuracy: 0.9793\n",
      "Epoch 27/30\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.0445 - accuracy: 0.9871 - val_loss: 0.1219 - val_accuracy: 0.9787\n",
      "Epoch 28/30\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.0426 - accuracy: 0.9881 - val_loss: 0.1176 - val_accuracy: 0.9803\n",
      "Epoch 29/30\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.0384 - accuracy: 0.9894 - val_loss: 0.1180 - val_accuracy: 0.9813\n",
      "Epoch 30/30\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.0396 - accuracy: 0.9888 - val_loss: 0.1143 - val_accuracy: 0.9796\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1e59696aac0>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=30, verbose=1, validation_split=0.2, batch_size = 32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PzFMH8_gez7O"
   },
   "source": [
    "95%이상의 성능을 가진 모델을 만들면 완성!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "id": "ZlEZeQZ5ez7P"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 0s - loss: 0.1148 - accuracy: 0.9808\n",
      "Accuracy: 0.9807999730110168\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(x_test,y_test, verbose=2)\n",
    "\n",
    "print('Accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "id": "sy77Zp4eez7P"
   },
   "source": [
    "![](https://www.tensorflow.org/versions/master/images/mnist_tensorboard.png)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "DL기초 과제.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
